{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word level Seq to Seq\n",
    "Note that this encoder decoder model is a word level encoder decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajdeep\\AppData\\Local\\conda\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # declaring the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 # number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.dirname(os.getcwd()), \"datasets\", \"fra-eng\", \"fra.txt\") # path to the corpus file\n",
    "# note that it is super important to know the format of the corpus file\n",
    "# in this case the format is such\n",
    "# <eng-text><tab><french-translation of the same eng text>\n",
    "# each new training example is in a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "input_words = set()\n",
    "target_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split(\"\\n\") # spliting training examples\n",
    "    \n",
    "lines = lines[:num_samples]\n",
    "lines = lines[::-1]\n",
    "\n",
    "# remember we are trying to get only `sample` number of lines and not any more for training \n",
    "for line in lines[:min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split(\"\\t\")\n",
    "    \n",
    "    target_text = '\\t' + target_text + \"\\n\"\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    # including chars in input and target characters\n",
    "#     for char in input_text:\n",
    "#         if char not in input_characters:\n",
    "#             input_characters.add(char)\n",
    "    \n",
    "#     for char in target_text:\n",
    "#         if char not in target_characters:\n",
    "#             target_characters.add(char)\n",
    "    for word in input_text.split(\" \"):\n",
    "        if word not in input_words:\n",
    "            input_words.add(word)\n",
    "    #note that the target words need to contain the tab and newline as separate words\n",
    "    for word in target_text.split(\" \"):\n",
    "        word = word.replace(\"\\t\", \"\")\n",
    "        word = word.replace(\"\\t\", \"\")\n",
    "        if word not in target_words:    \n",
    "            target_words.add(word)\n",
    "    \n",
    "input_words.add(\".\")\n",
    "\n",
    "target_words.add(\"\\n\")\n",
    "target_words.add(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3998\n",
      "Number of unique input tokens: 845\n",
      "Number of unique output tokens: 1645\n",
      "Max sequence length for inputs: 4\n",
      "Max sequence length for outputs: 9\n"
     ]
    }
   ],
   "source": [
    "# here input_characters is the total number of input characters\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "input_words = sorted(list(input_words))\n",
    "target_words = sorted(list(target_words))\n",
    "\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "\n",
    "\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "max_encoder_seq_length = max([len(txt.split(\" \")) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt.split(\" \")) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples: \" + str(len(input_texts))) # total number of samples that we are training\n",
    "print(\"Number of unique input tokens: \" + str(num_encoder_tokens))\n",
    "print(\"Number of unique output tokens: \" + str(num_decoder_tokens))\n",
    "print(\"Max sequence length for inputs: \" + str(max_encoder_seq_length))\n",
    "print(\"Max sequence length for outputs: \" + str(max_decoder_seq_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that here we are only taking the first 1000 training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
    "# recall that input_characters is a list of all the unique input characters that we have in the 1000 training examples\n",
    "# that we have read so far\n",
    "\n",
    "# what enumerate does is that it assigns a counter to the unique characters, so basically if we get the following list\n",
    "# a = [\"ola\", \"mundo\", \"keras\"], we would get back from enumerate 1, \"ola\"; 2, \"mundo\"; 3, \"keras\"\n",
    "\n",
    "# target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "target_token_index = dict([(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the important part as we are defining what goes into the input data\n",
    "# max_encoder seq length is the maximum number of characters in one training example in the entire corpus\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "\n",
    "# the number of input_texts and the number of target_texts will be the same\n",
    "decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "# here we just created the vectors that we are going to use as inputs for the encoder and inputs and targets for the \n",
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    input_text_words = input_text.split(\" \") # the following 2 lines to be included for word level enc-dec\n",
    "    target_text_words = target_text.split(\" \")\n",
    "    for t, word in enumerate(input_text_words):\n",
    "        # i is the first index as it is the ith training example \n",
    "        # t is the second index as the t-th character in ith training example\n",
    "        if \".\" in word and word[- 1] != \".\": # patchy method of considering punctuations '.' and ',' as separate words\n",
    "            period_split_words = word.split(\".\")\n",
    "            encoder_input_data[i, t, input_token_index[\".\"]] = 1\n",
    "            encoder_input_data[i, t, input_token_index[period_split_words[1]]] = 1\n",
    "        else:\n",
    "            encoder_input_data[i, t, input_token_index[word]] = 1\n",
    "            \n",
    "    for t, word in enumerate(target_text_words):\n",
    "        # here a tb splitting must be done in order to treat the tab as a separate word\n",
    "        if \"\\t\" in word:\n",
    "            tab_split_words = word.split(\"\\t\")\n",
    "            decoder_input_data[i, t, target_token_index[\"\\t\"]] = 1\n",
    "            decoder_input_data[i, t, target_token_index[tab_split_words[1]]] = 1\n",
    "        else:\n",
    "            decoder_input_data[i, t, target_token_index[word]] = 1\n",
    "        \n",
    "        # Here is an important thing to understand\n",
    "        ###############---------------------------IMPORTANT------------------------#####################\n",
    "        # The decoder_target_data will be ahead of the decoder_input_data by one time step and this is an important factor\n",
    "        # The decoder_target_data will obviously not contain the first character\n",
    "        if t > 0:\n",
    "            if \"\\t\" in word:\n",
    "                tab_split_words = word.split(\"\\t\")\n",
    "                decoder_target_data[i, t-1, target_token_index[\"\\t\"]] = 1\n",
    "                decoder_target_data[i, t-1, target_token_index[tab_split_words[1]]] = 1\n",
    "            else:\n",
    "                decoder_target_data[i, t - 1, target_token_index[word]] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens)) # num_encoder_tokens is essentially the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "# Each unit or cell of LSTM within the layer has an internal cell state referred to as c and a hidden state referred\n",
    "# to as h. \n",
    "# If we need to access the internal state c of the last time step we need to use return_state = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# here the encoder_outputs would be hidden state at last time step, state_h would be the hidden state of the last time step\n",
    "# again and state_c is the internal state of the last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c] # we will only keep the states and discard the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# return sequences will return the hidden states for each and every time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# note here we are passing the encoder_states as the initial_state of the decoder lstm\n",
    "# decoder_outputs will actially contain the hidden states of all the time steps as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# Dense is an ordinary dense neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3198 samples, validate on 800 samples\n",
      "Epoch 1/100\n",
      "3198/3198 [==============================] - 48s 15ms/step - loss: 1.3698 - val_loss: 1.0196\n",
      "Epoch 2/100\n",
      "3198/3198 [==============================] - 52s 16ms/step - loss: 1.2137 - val_loss: 0.9631\n",
      "Epoch 3/100\n",
      "3198/3198 [==============================] - 45s 14ms/step - loss: 1.1446 - val_loss: 0.9062\n",
      "Epoch 4/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 1.0699 - val_loss: 0.8699\n",
      "Epoch 5/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.9927 - val_loss: 0.8074\n",
      "Epoch 6/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.9219 - val_loss: 0.7677\n",
      "Epoch 7/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.8602 - val_loss: 0.7289\n",
      "Epoch 8/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.8013 - val_loss: 0.6945\n",
      "Epoch 9/100\n",
      "3198/3198 [==============================] - 48s 15ms/step - loss: 0.7488 - val_loss: 0.6693\n",
      "Epoch 10/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.6976 - val_loss: 0.6363\n",
      "Epoch 11/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.6522 - val_loss: 0.6080\n",
      "Epoch 12/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.6073 - val_loss: 0.5730\n",
      "Epoch 13/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.5665 - val_loss: 0.5431\n",
      "Epoch 14/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.5282 - val_loss: 0.5355\n",
      "Epoch 15/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.4933 - val_loss: 0.4984\n",
      "Epoch 16/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.4602 - val_loss: 0.4712\n",
      "Epoch 17/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.4278 - val_loss: 0.4472\n",
      "Epoch 18/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.3980 - val_loss: 0.4139\n",
      "Epoch 19/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.3702 - val_loss: 0.3915\n",
      "Epoch 20/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.3433 - val_loss: 0.3727\n",
      "Epoch 21/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.3189 - val_loss: 0.3474\n",
      "Epoch 22/100\n",
      "3198/3198 [==============================] - 43s 14ms/step - loss: 0.2976 - val_loss: 0.3478\n",
      "Epoch 23/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.2767 - val_loss: 0.3183\n",
      "Epoch 24/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.2595 - val_loss: 0.2870\n",
      "Epoch 25/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.2412 - val_loss: 0.2768\n",
      "Epoch 26/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.2271 - val_loss: 0.2749\n",
      "Epoch 27/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.2117 - val_loss: 0.2393\n",
      "Epoch 28/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.1993 - val_loss: 0.2266\n",
      "Epoch 29/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.1884 - val_loss: 0.2154\n",
      "Epoch 30/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.1768 - val_loss: 0.2069\n",
      "Epoch 31/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1668 - val_loss: 0.1941\n",
      "Epoch 32/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1578 - val_loss: 0.1761\n",
      "Epoch 33/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1502 - val_loss: 0.1660\n",
      "Epoch 34/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1420 - val_loss: 0.1600\n",
      "Epoch 35/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1351 - val_loss: 0.1527\n",
      "Epoch 36/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1285 - val_loss: 0.1496\n",
      "Epoch 37/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1239 - val_loss: 0.1340\n",
      "Epoch 38/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.1184 - val_loss: 0.1269\n",
      "Epoch 39/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1138 - val_loss: 0.1254\n",
      "Epoch 40/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1100 - val_loss: 0.1144\n",
      "Epoch 41/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1069 - val_loss: 0.1075\n",
      "Epoch 42/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.1031 - val_loss: 0.1062\n",
      "Epoch 43/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0998 - val_loss: 0.1054\n",
      "Epoch 44/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0974 - val_loss: 0.0996\n",
      "Epoch 45/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0950 - val_loss: 0.1030\n",
      "Epoch 46/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0928 - val_loss: 0.0962\n",
      "Epoch 47/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.0907 - val_loss: 0.0918\n",
      "Epoch 48/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0892 - val_loss: 0.0840\n",
      "Epoch 49/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0867 - val_loss: 0.0817\n",
      "Epoch 50/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0849 - val_loss: 0.0797\n",
      "Epoch 51/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0836 - val_loss: 0.0777\n",
      "Epoch 52/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0820 - val_loss: 0.0753\n",
      "Epoch 53/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0811 - val_loss: 0.0754\n",
      "Epoch 54/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0794 - val_loss: 0.0733\n",
      "Epoch 55/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0783 - val_loss: 0.0723\n",
      "Epoch 56/100\n",
      "3198/3198 [==============================] - 41s 13ms/step - loss: 0.0774 - val_loss: 0.0693\n",
      "Epoch 57/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.0761 - val_loss: 0.0683\n",
      "Epoch 58/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.0754 - val_loss: 0.0695\n",
      "Epoch 59/100\n",
      "3198/3198 [==============================] - 40s 13ms/step - loss: 0.0749 - val_loss: 0.0652\n",
      "Epoch 60/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0738 - val_loss: 0.0649\n",
      "Epoch 61/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0732 - val_loss: 0.0653\n",
      "Epoch 62/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0721 - val_loss: 0.0643\n",
      "Epoch 63/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0715 - val_loss: 0.0616\n",
      "Epoch 64/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0713 - val_loss: 0.0616\n",
      "Epoch 65/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.0701 - val_loss: 0.0609\n",
      "Epoch 66/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0698 - val_loss: 0.0612\n",
      "Epoch 67/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0693 - val_loss: 0.0581\n",
      "Epoch 68/100\n",
      "3198/3198 [==============================] - 42s 13ms/step - loss: 0.0688 - val_loss: 0.0593\n",
      "Epoch 69/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.0680 - val_loss: 0.0582\n",
      "Epoch 70/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.0678 - val_loss: 0.0591\n",
      "Epoch 71/100\n",
      "3198/3198 [==============================] - 43s 13ms/step - loss: 0.0672 - val_loss: 0.0559\n",
      "Epoch 72/100\n",
      "3198/3198 [==============================] - 47s 15ms/step - loss: 0.0669 - val_loss: 0.0578\n",
      "Epoch 73/100\n",
      "3198/3198 [==============================] - 55s 17ms/step - loss: 0.0666 - val_loss: 0.0567\n",
      "Epoch 74/100\n",
      "3198/3198 [==============================] - 52s 16ms/step - loss: 0.0665 - val_loss: 0.0572\n",
      "Epoch 75/100\n",
      "3198/3198 [==============================] - 53s 16ms/step - loss: 0.0654 - val_loss: 0.0544\n",
      "Epoch 76/100\n",
      "3198/3198 [==============================] - 55s 17ms/step - loss: 0.0659 - val_loss: 0.0548\n",
      "Epoch 77/100\n",
      "3198/3198 [==============================] - 53s 17ms/step - loss: 0.0652 - val_loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "3198/3198 [==============================] - 53s 17ms/step - loss: 0.0649 - val_loss: 0.0532\n",
      "Epoch 79/100\n",
      "3198/3198 [==============================] - 54s 17ms/step - loss: 0.0649 - val_loss: 0.0527\n",
      "Epoch 80/100\n",
      "3198/3198 [==============================] - 56s 18ms/step - loss: 0.0644 - val_loss: 0.0525\n",
      "Epoch 81/100\n",
      "3198/3198 [==============================] - 53s 17ms/step - loss: 0.0640 - val_loss: 0.0519\n",
      "Epoch 82/100\n",
      "3198/3198 [==============================] - 53s 16ms/step - loss: 0.0639 - val_loss: 0.0530\n",
      "Epoch 83/100\n",
      "3198/3198 [==============================] - 53s 17ms/step - loss: 0.0637 - val_loss: 0.0519\n",
      "Epoch 84/100\n",
      "3198/3198 [==============================] - 52s 16ms/step - loss: 0.0634 - val_loss: 0.0515\n",
      "Epoch 85/100\n",
      "3198/3198 [==============================] - 51s 16ms/step - loss: 0.0636 - val_loss: 0.0503\n",
      "Epoch 86/100\n",
      "3198/3198 [==============================] - 54s 17ms/step - loss: 0.0625 - val_loss: 0.0507\n",
      "Epoch 87/100\n",
      "3198/3198 [==============================] - 54s 17ms/step - loss: 0.0627 - val_loss: 0.0502\n",
      "Epoch 88/100\n",
      "3198/3198 [==============================] - 51s 16ms/step - loss: 0.0631 - val_loss: 0.0508\n",
      "Epoch 89/100\n",
      "3198/3198 [==============================] - 52s 16ms/step - loss: 0.0619 - val_loss: 0.0494\n",
      "Epoch 90/100\n",
      "3198/3198 [==============================] - 58s 18ms/step - loss: 0.0619 - val_loss: 0.0479\n",
      "Epoch 91/100\n",
      "3198/3198 [==============================] - 54s 17ms/step - loss: 0.0620 - val_loss: 0.0484\n",
      "Epoch 92/100\n",
      "3198/3198 [==============================] - 53s 16ms/step - loss: 0.0615 - val_loss: 0.0488\n",
      "Epoch 93/100\n",
      "3198/3198 [==============================] - 55s 17ms/step - loss: 0.0616 - val_loss: 0.0492\n",
      "Epoch 94/100\n",
      "3198/3198 [==============================] - 51s 16ms/step - loss: 0.0617 - val_loss: 0.0489\n",
      "Epoch 95/100\n",
      "3198/3198 [==============================] - 52s 16ms/step - loss: 0.0615 - val_loss: 0.0476\n",
      "Epoch 96/100\n",
      "3198/3198 [==============================] - 53s 17ms/step - loss: 0.0608 - val_loss: 0.0491\n",
      "Epoch 97/100\n",
      "3198/3198 [==============================] - 54s 17ms/step - loss: 0.0613 - val_loss: 0.0478\n",
      "Epoch 98/100\n",
      "3198/3198 [==============================] - 51s 16ms/step - loss: 0.0608 - val_loss: 0.0480\n",
      "Epoch 99/100\n",
      "3198/3198 [==============================] - 51s 16ms/step - loss: 0.0604 - val_loss: 0.0469\n",
      "Epoch 100/100\n",
      "1984/3198 [=================>............] - ETA: 17s - loss: 0.0585"
     ]
    }
   ],
   "source": [
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# passing all the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8VGW+x/HPbybJpAdIQg1IL9IlIIq9o1hWd1Vcuy7u1V11d/Wqe9etd/ted+29rn3trnVVsIKKiIogUgQJYAgBUkmd5/7xDCFggFAmk8x836/XvMicOTPndzLkfM95nnOeY845REREAAKxLkBERNoPhYKIiDRRKIiISBOFgoiINFEoiIhIE4WCiIg0USiItJKZ3Wdm/9vKeZeZ2RG7+zkibU2hICIiTRQKIiLSRKEgcSXSbHOlmX1qZlVmdreZdTOzl8yswsxeM7POzeY/wcw+N7MNZjbDzIY1e22smc2JvO8xIHWrZU0xs7mR975nZqN2seYfmNliM1tnZs+ZWc/IdDOzv5vZGjMri6zTiMhrx5rZ/EhtK83sil36hYlsRaEg8egU4EhgMHA88BLwcyAP/3/+UgAzGww8AlwO5AMvAs+bWYqZpQDPAP8EugD/inwukffuA9wDXATkArcDz5lZaGcKNbPDgD8CpwI9gOXAo5GXjwIOiqxHJ+A0oDTy2t3ARc65LGAE8MbOLFdkWxQKEo9udM4VO+dWAm8D7zvnPnbO1QJPA2Mj850GvOCc+49zrh74G5AG7A9MBJKBfzjn6p1zTwAfNlvGD4DbnXPvO+canXP3A7WR9+2M7wP3OOfmROq7BtjPzPoC9UAWMBQw59wC59zqyPvqgb3NLNs5t945N2cnlyvSIoWCxKPiZj9vbOF5ZuTnnvg9cwCcc2FgBdAr8tpKt+WIkcub/bwX8LNI09EGM9sA9I68b2dsXUMl/migl3PuDeAm4Gag2MzuMLPsyKynAMcCy83sTTPbbyeXK9IihYIkslX4jTvg2/DxG/aVwGqgV2TaJn2a/bwC+L1zrlOzR7pz7pHdrCED3xy1EsA5d4NzbhwwHN+MdGVk+ofOuROBrvhmrsd3crkiLVIoSCJ7HDjOzA43s2TgZ/gmoPeAmUADcKmZJZnZycCEZu+9E/ihme0b6RDOMLPjzCxrJ2t4GDjPzMZE+iP+gG/uWmZm4yOfnwxUATVAY6TP4/tmlhNp9ioHGnfj9yDSRKEgCcs5txA4E7gRWIvvlD7eOVfnnKsDTgbOBdbj+x+eavbe2fh+hZsiry+OzLuzNbwOXAs8iT86GQCcHnk5Gx8+6/FNTKX4fg+As4BlZlYO/DCyHiK7zXSTHRER2URHCiIi0kShICIiTRQKIiLSRKEgIiJNkmJdwM7Ky8tzffv2jXUZIiIdykcffbTWOZe/o/k6XCj07duX2bNnx7oMEZEOxcyW73guNR+JiEgzCgUREWmiUBARkSYdrk+hJfX19RQVFVFTUxPrUqIuNTWVgoICkpOTY12KiMShuAiFoqIisrKy6Nu3L1sOahlfnHOUlpZSVFREv379Yl2OiMShuGg+qqmpITc3N64DAcDMyM3NTYgjIhGJjbgIBSDuA2GTRFlPEYmNuGg+EpEEUlMOX74MFoBgCmR2hd77wu7sMDkH856EbiOg69A9V+vuqqv2/yan7d767QSFwh6wYcMGHn74YS6++OKdet+xxx7Lww8/TKdOnaJUmUgb2bgBUnO2veEKh+Hdv0PJl34Dl5LhN+iBJAgmQ1YPv2HPHQiB7TRgNNbDw6fB1+9tOb3fQXDs3yB/CNRVwaePw6JXod/BMPp0SNvO35hz8Nqv4N3rIT0XznsZ8gdvfn3tIr/cbntvo6YG+HomlK3woZI/1K9X8TxYOh3WfAEZuX4dUztB9Vqo+AZqK2DAYTBksv+dbKpl3VL48hVY+CIsfw9cI2CQkgn7/wgOuXrb67IHdLj7KRQWFrqtr2hesGABw4YNi1FFsGzZMqZMmcK8efO2mN7Y2EgwGNzjy4v1+ooAULXW711/8iismgN99oOj/wC99tlyPufgpavgg9shuwAaa/0ecGMdhOu3nDetM4z8Hhz9Rwi2sM/60lXw/m0w5R/Q9wBoqIGvZ8Ebv/NhMPQ4WPom1GyAzG5QWQzJ6TD8ZOg+AtLzIDPfb7wz8nxYvXy1r23UabBkug+p81/xG/G3/wZv/sVvmPsdDJMu9eG1dhGULIRl78CXL0F16eYagyk+9Dau988zu/ufG2s3z5Oc4devpgxSsmDg4f73+c1nUFvm5+m6Nww6yv9O6qr8o+8BMPTYXfq6zOwj51zhjubTkcIecPXVV7NkyRLGjBlDcnIymZmZ9OjRg7lz5zJ//nxOOukkVqxYQU1NDZdddhnTpk0DNg/ZUVlZyeTJkznggAN477336NWrF88++yxpaWkxXjPZQvkqv0eX1rl18zsH9RshJT26dYHfuLzxe6ir9HvNfQ+EnF5bzhNuhJk3wZev+g1UYx0Ekv182QV+Yz7ilB03U6ycA7Nuhc+f9hv17iNh/0th7sNw56Ew+gzY7xLoNtx/1hu/8xvd/X8MR/5uy893zte1/iu/cV86Az64AyrXwCl3+Q30Jp885gNh3/+CwvM2T+8+EoZ/B177tQ+pwUfDhIugz0RYPRdm3wOfPQlzH9xyPXIHQkZXf9Qx8RI4+vd+o3zfcfDP7/jvuegDHxZdh8Gs2+DBU7b8jFC2X97QKf4IoXgerP4ENq6DvQ6A/odAdg+/njUbfDhk5EMoy6/3snfgs8dh8Rv+exh5il+f/odAl/6t+eb3uLg7UvjN858zf1X5Hl3m3j2z+dXxw7f5evMjhRkzZnDccccxb968ptNG161bR5cuXdi4cSPjx4/nzTffJDc3d4tQGDhwILNnz2bMmDGceuqpnHDCCZx5Zst3WNSRQgxUroGb9/V/zBf8B7K6bX/+6nXwr3OhaDYc9gvY9yIIRI4aw41QvhKyera8N7yzVs6BJ86DDSsgNXvzHmqvQjjwpzB4st9jfuoHsOxt6DHGb/CSQn5Pu2ylr6e+evPGsfmGu6wIVs31G7ulM/yGMiUTxp4J+5ztN/7gg+nt//OB0VgHnfv5vfMFz8O4c/3efWvaxd+7EV79BQw7Hk65B6rW+OW+8DO/Tmc/s2VYtEY47DfKVWuhYrU/svn6fb8RH3smHHzV5tqWv+dDIRiCKdfByO/66Q21MO8p/7vKH+JDoHO/PfMdtgEdKcTQhAkTtriO4IYbbuDpp58GYMWKFSxatIjc3Nwt3tOvXz/GjBkDwLhx41i2bFmb1Ss74Bz8+yf+8L2hBh46Bc590W+AW1I8Hx6d6o8sehXCK9fAp4/5vedlb8MXL/p25WDIb1y6DYeC8b75JX/ot9vUayt8U0X9xk0F+c7WjeuhdDHMvNk3lZz3IhRMiLRlz4DZd8OjZ0D+ML9hrd8IJ94CY8749sY5HIZXfg6zbvZHG1P+7sNmxh9gyRt+Hgv4Jo2j/whjv+/7EJpLzYEjfwv7/Qi+eMGHwcKX/J72cde1vqN0/x/7NvmXr4a/DfIbc/B7zt+7d+cDAfzvNL2Lf+QPhv4Hb3vevfaHH77jdwCyum+enhSCMVN3ftkdTNyFwvb26NtKRkZG088zZszgtddeY+bMmaSnp3PIIYe0eJ1BKBRq+jkYDLJx48ZvzSMx8vlT8MW/4Yjf+D3fh0/zG9szn/R7jxWrfSfjhq9h3Ve+uSIlwwdHQaFvZnnpKr+nnpLlmxv6TIQNy2HNAlj8OnzyiF9WKNtviNLz/EapdJHveNyeoVPghBv9Bg+gxyj/mHixr/3dG6DLADjx5i07UJsLBOCYP0IoE976K3z1lm/SSc+Fw671zRld925dU1hmV9+8U3ieD6Kk1J0/c2bif/lO2UWv+sDsO8n3AwT2fB9di/IGtc1y2qG4C4VYyMrKoqKiosXXysrK6Ny5M+np6XzxxRfMmjWrjauLA8ve8U0co0/b/c/auB6+mQdr5vu973A9WNDvfQ6ZDP0P3XIDVrkGXrgCeo3ze8DBJDjpVr+B/2OBbyZpLpDsN/gn3wHZPf20ESf7s0zWLICeYyE5dcv3OAfrl/k29VVzfFNPVak/0ug23LfRdxvuQwJ8faEs3wSU1sVvyFsSTIJRp/pHa5j5pq5QFnxwlw/B8Rdu+/NbI3k3+sXGTE2IPfP2RqGwB+Tm5jJp0iRGjBhBWloa3bptbm8+5phjuO222xg1ahRDhgxh4sSJMay0AypZCA+dCvVVUFsOE36w+bXSJb6JY/h3tmzXLV/lzyIZePjmw/+acpj+B9+J6Rr9tNROfi/WNfqzYT64I9IO/zN/CuM3n8FnT/hmo5Nu3byMUaf6M0y+nuU7EbN6+gDovJc/Y6Wlvdm0TrDXfi2voxl06ecf7WEjOOky/5CEFHcdzXHNOairZMHi5QwbPiLW1ey+xnrfoZiR7zdCW7cV11bAnYf5vfseo30zy3fv8SHwySN+D76+CrqP8p2YPcfAB3fCG/8LdRW+XXrY8dB7Irxznd/rH3eOn9ZthG+H33RU0FDrz5555zrfDLRJeh4c/kv/PpEOTB3N8ah6rT8TpLwEHvszjD3L7w033zP95jN/lkZdtT+1rcco3wFYX+2nZXb15zrnFPgN4YLn4aP7/HtPuGHnToNrqPWdnHMf8udwj7+w5Qt8Kr6BFe/7vfBNp0k2NsCTF8L8Z/zz+c/4TtAeo/xz5+C5S31H6tnP+nblf54MT03zgbDoVX/K3+jTYfrv4a7DoXNf3w4+4HA44Cf+qtePH/Rt+j3GwNRHfDNQS5JCvg187Jn+fcGQ//1ldW+zK0lF2gMdKbS1cIPvfNvUPtwS53xbdTBl8waprspfMBPKZMHyEoa9dqYPic79/Fkto6f6s03e+F/f1txtBHzzKVSVtLyMzv38nnj1Wr8xrSkDF4ZT7oZBR+54PRa/5jtPSxf7De038/y5770n+maQpFR/tsqKyGl/AElpfmO93yXw/GUw7wk46vd++f/+iT+3u/+hvpO2ocZvnI/4tX8P+Ktm7zvO9wccfDUcdIUPxJpyv95LXodDf+4vVGr6vVVH2vLHtF0npUg71NojhaiFgpn1Bh4AugNh4A7n3PVbzWPA9cCxQDVwrnNuzvY+t8OHwoav/dWP2T1980VLKr7xZ7SEsvxFRYGgb1s3g/whLFi4iGGDBsDCF+C9m2DlbB8gjXX+TJTjb/CX1QNUFPsmluQM3+m3YTl89bbvvA0m+fPM+x8GZV/DY2f6jfu4cyJt40n+KKPbcB8yFvAb8tn3+ouCugyAyX+BQUf4jtG5D/o2+I0boGGjr6f7KH8006vQh9bnT/ta6qu23OBXr/MXH6362Idm/Ub/ucf9fctTNGvKfTNQ3sAofkki8ac9hEIPoIdzbo6ZZQEfASc55+Y3m+dY4Mf4UNgXuN45t+/2PrfDhELVWr9R3HQGCvgjgOJ5/pxwwpDdyzfnNFdT5k9BTI7sLbvw5g1+3mBISd9yfZ3z467MfdifXz166q43d9RVw4tX+uaZTZ2xzQVD/mig695QeL4PlKTQt+fbnmXv+CtvhxyjzkyRNhTzPgXn3GpgdeTnCjNbAPQC5jeb7UTgAeeTaZaZdTKzHpH3dmyVa/wGNCPPb9TBNwGFG6DTXn7jX77Sb9Qz8v3ecEMNrF/um1lyB/hAKF/lm1U69Wn5HHEzHwZ77b/7Naekw0k3+0e40XcEb1znjx6++dQH3fDvQO8Jux48fQ+A81/a/VpFJCrapKPZzPoCY4H3t3qpF7Ci2fOiyLQtQsHMpgHTAPr06ROtMvechrrNg19Vr988JEJNGWD+Sti0TrDeQcUqqPzGNxU1RC5q69Iv0v4d9Kc55hS0fXt4IOgfyZHTLQcf1bbLF5GYiPpNdswsE3gSuNw5t/WgRC3tbn6rPcs5d4dzrtA5V5ifnx+NMnfLhg0buOWWWzZPqI1cyBZI9nvazkUGxCrzY8YEknz7fOd+/OOhV6h2ab7ppqHOd7pu3SSjDlIRaSNRDQUzS8YHwkPOuadamKUI6N3seQGwKpo1RUOLoRBI9qczNtT400Ebav3RQ1qz8WLM+MfNt1Gd0sV35nYfse3xdERE2kDUmo8iZxbdDSxwzl23jdmeA35kZo/iO5rLOmJ/QvOhs4884gi6pod5/N+vU9sQ5jtH7M9vfvkLqmrqOfWsSykqKaMxHObaa6+luLiYVatWceihh5KXl8f06dNjvSoikuCi2acwCTgL+MzM5kam/RzoA+Ccuw14EX/m0WL8KanntfA5O+elq/0FXHtS95Ew+U/bfPlPf/oT8+bNY+7cubz6wnM88ch9fPD2G7i0zpww+Ujemv4aJesr6NmzBy+8/jbgx0TKycnhuuuuY/r06eTl5e3ZmkVEdkE0zz56h5b7DJrP44BLolVDLLz6yku8+uYsxk46DDAqK8pZtHQZB04YyxW/ncVVV13FlClTOPDAA2NdqojIt8TfMBfb2aNvC66hlmsum8ZFV/w6MsFB8ecQruej92fy4n+mc80113DUUUfxy1/+Mqa1iohsLepnHyWCpqGzw2GOPnA89zz6LJWVlQCsXLWKNRth1boq0rO7cOaZZ3LFFVcwZ86cLd8rItIOxN+RQlurKSc3zZi0//6MGDmCyQcVcsbpp7Pffn6Y5MzMTB588EEWr1zJlWfsSyAQIDk5mVtvvRWAadOmMXnyZHr06KGOZhGJOQ2Itzsa6vxga4T9dQeB5Mh4PyOjem1BuxzWQ0TatdYOc6Hmo91RsRpw/oKztM5+CItQti42E5EOS81Hu6quyl+tnNk1clvEzpDTe8fvExFpx+LmSCHqzWCbhqrY9HP5Kj9cRfPhr82ifkOWjtbcJyIdS1wcKaSmplJaWkpubi62pzfKzvnRQStW+2ahtE4+DOoqIwPVtd2v0DlHaWkpqampO55ZRGQXxEUoFBQUUFRUREnJNu4ytqsaav39gRvr/J3EMGhYCTh/P+ENIbC1e3aZO5CamkpBQUGbLlNEEkdchEJycjL9+vXbcx/onL+B++u/8zfCOeYPMOwo3zRUvc7firLnWMgbtOeWKSLSDsRFKOxRdVXw7I/g86dgxClwwo3+nsGbpHeBUafGrj4RkShSKDRXvxHuOcYPqHfEb/ztIqPccSwi0p4oFJr75FF/28nv3edvOykikmDi5pTU3eYcvH8bdB8Fe58U62pERGJCobDJ0ulQ8gVMvFhNRiKSsBQKm8y6FTK6woiTY12JiEjMKBQA1i6GRa/C+AsgKRTrakREYkahAL4vIZgChefHuhIRkZhSKFSWwNyHYeT3/OB2IiIJLLFDoaEOHj8bXCPsf2msqxERibnEvU7BOXjxZ/D1e/Dde6Dr0FhXJCISc4l7pPDBHTDnATjwCj+chYiIJGgorPgQXr4GhhwHh/5PrKsREWk3Ei8Uwo3wwk/9zXFOvh0CifcrEBHZlsTrU5h9jx/f6Lv3Qigr1tWIiLQribWbXLUW3vgd9DtIA96JiLQgsULhtV/7+yUc+zeNbyQi0oLECYUVH8LH//QD3uUPiXU1IiLtUuKEggVgwGFw8H/HuhIRkXYrcTqaC8bBWU/HugoRkXYtcY4URERkhxQKIiLSRKEgIiJNFAoiItJEoSAiIk0UCiIi0kShICIiTRQKIiLSJGqhYGb3mNkaM5u3jdcPMbMyM5sbefwyWrWIiEjrRPOK5vuAm4AHtjPP2865KVGsQUREdkLUjhScc28B66L1+SIisufFuk9hPzP7xMxeMrPh25rJzKaZ2Wwzm11SUtKW9YmIJJRYhsIcYC/n3GjgRuCZbc3onLvDOVfonCvMz89vswJFRBJNzELBOVfunKuM/PwikGxmebGqR0REYhgKZtbdzN/+zMwmRGopjVU9IiISxbOPzOwR4BAgz8yKgF8ByQDOuduA7wL/ZWYNwEbgdOeci1Y9IiKyY1ELBefc1B28fhP+lFUREWknYn32kYiItCMKBRERaaJQEBGRJgoFERFpolAQEZEmCgUREWmiUBARkSYKBRERaaJQEBGRJgoFERFpkjChUFpZy2vzi6ltaIx1KSIi7VbChMJ7S0q58IHZLFlTFetSRETarYQJhUHdMgFYXFIZ40pERNqvhAmFfnkZBAwWF1fEuhQRkXYrYUIhlBSkb24Gi9boSEFEZFsSJhQABnbNVCiIiGxHwoXCsrVV1DeGY12KiEi7lFChMKhbJg1hx/JSnYEkItKSxAqFrlkALCpWE5KISEsSKhQG5GdihvoVRES2IaFCIS0lSEHnNIWCiMg2JFQoAAzMz2SxQkFEpEUJFwqDumWxpKSSxrCLdSkiIu1OwoXCwK6Z1DWEWbGuOtaliIi0OwkXCoO6+jGQ1K8gIvJtCRcKAyOhoH4FEZFva1UomNllZpZt3t1mNsfMjop2cdGQlZpM9+xUFq3RwHgiIltr7ZHC+c65cuAoIB84D/hT1KqKskHddAaSiEhLWhsKFvn3WOBe59wnzaZ1OAO7+lAI6wwkEZEttDYUPjKzV/Gh8IqZZQEddlS5QV2zqK5rZFXZxliXIiLSrrQ2FC4ArgbGO+eqgWR8E1KHNLp3DgB3vf1VjCsREWlfWhsK+wELnXMbzOxM4BdAWfTKiq7hPXM4d/++3PfeMl5fUBzrckRE2o3WhsKtQLWZjQb+G1gOPBC1qtrANccOZe8e2Vzxr08oLq+JdTkiIu1Ca0OhwTnngBOB651z1wNZ0Ssr+kJJQW48Yyw19WEuf3Suhr0QEaH1oVBhZtcAZwEvmFkQ36/QoQ3Iz+Q3Jw5n5tJSfvnsPHzuiYgkrqRWzncacAb+eoVvzKwP8NfoldV2vjeugCUlldz+5lJCSUGunTIMsw57tq2IyG5pVShEguAhYLyZTQE+cM516D6FTcyMq48ZSm19mHve/YrU5ABXHj1EwSAiCalVoWBmp+KPDGbgL1q70cyudM49EcXa2oyZ8avj96a2oZFbZiwhlBTksiMGxbosEZE219rmo//BX6OwBsDM8oHXgLgIBfDB8PuTRlLbEObvr31JKDnADw8eEOuyRETaVGs7mgObAiGidEfvNbN7zGyNmc3bxutmZjeY2WIz+9TM9mllLVETCBh//e5ojh/dkz+99AX3vquL20QksbT2SOFlM3sFeCTy/DTgxR285z7gJrZ9PcNkYFDksS/+Woh9W1lP1AQDxnWnjqa+Icxvnp9PanKQqRP6xLosEZE20aojBefclcAdwChgNHCHc+6qHbznLWDddmY5EXjAebOATmbWo3VlR1dyMMANU8dy6JB8/ufpz3jxs9WxLklEpE209kgB59yTwJN7cNm9gBXNnhdFpn1rC2xm04BpAH36tM1ee0pSgFu+P46z7n6fyx79mKzUJA4clN8myxYRiZUd9QtUmFl5C48KMyvfzWW3dM5ni1ePOefucM4VOucK8/PbbsOclhLk7nPGMyA/k4v++RFzV2xos2WLiMTCdkPBOZflnMtu4ZHlnMvezWUXAb2bPS8AVu3mZ+5xOenJPHD+BHIzUzj/vg/5am1VrEsSEYmaWN6j+Tng7MhZSBOBMudcu2y875qdygPn+z7wc+75gJKK2hhXJCISHVELBTN7BJgJDDGzIjO7wMx+aGY/jMzyIrAUWAzcCVwcrVr2hH55Gdx9TiFrKmq44P4PqaptiHVJIiJ7nHW0QeAKCwvd7NmzY7b81xcU84MHZnPgoHzuOqeQ5GAsD7ZERFrHzD5yzhXuaD5t0XbS4cO68ceTR/LmlyVc+a9PdJ9nEYkrrT4lVTY7bXwf1lbW8ddXFpKbGeIXx2lkVRGJDwqFXXTxIQMoqajl7ne+IjczhYsPGRjrkkREdptCYReZGb+csjfrqur4y8sL6ZSWwhn7ajgMEenYFAq7IRAw/u/U0VTU1PM/z3xGVmoSx4/uGeuyRER2mTqad1Ny0A+HMX6vLvz08bnMWLhmx28SEWmnFAp7QFpKkLvOLWRwtyx++OBHvL+0NNYliYjsEoXCHpKd6ofDKOiczgX3z+YTjZMkIh2QQmEPys0M8eAF+9I5I5mz7/mABat3d8xAEZG2pVDYw7rnpPLwhRNJSw5y5l3vM3+VgkFEOg6FQhT07pLOwz/Yl5SkAFPvnKWmJBHpMBQKUdI/P5PHL9qP7LQkvn/X+3y4bHs3oRMRaR8UClHUu0s6j1+0H12zQpx99wc6XVVE2j2FQpT1yEnjsYv2o39+BhfeP5tn566MdUkiItukUGgD+VkhHpk2kXF7debyx+Zy37tfxbokEZEWKRTaSHZqMvefP4Ejh3Xj18/P55fPzqO+MRzrskREtqBQaEOpyUFuPXMcFx3UnwdmLufsuz9gfVVdrMsSEWmiUGhjwYBxzbHDuO7U0Xz09XpOuPkdXcsgIu2GQiFGTt6ngMemTaSuIczJt77L0x8XxbokERGFQiyN7dOZf//4QEYXdOInj33Cr56dR12D+hlEJHYUCjGWnxXiwQv35cID+nH/zOVMvXMWxeU1sS5LRBKUQqEdSA4G+MWUvblx6lgWrC7nuBve0fDbIhITCoV25PjRPXnmkklkpSZxxl3vc887X+Gci3VZIpJAFArtzOBuWTz7o0kcNrQrv/33fC5/bC7VdQ2xLktEEoRCoR3KTk3m9jPHceXRQ3juk1WcfMt7fF1aHeuyRCQBKBTaqUDAuOTQgdx/3gRWl9Vwws3v8N6StbEuS0TinEKhnTtocD7P/WgSeZkhzrr7A/45c1msSxKROKZQ6AD2ys3g6Yv35+DB+Vz77Odc9cSn1NQ3xrosEYlDCoUOIis1mTvPLuSSQwfw2OwVnHr7TFZu2BjrskQkzigUOpBgwLjy6KHcftY4lpZUcfyN7zBdN+4RkT1IodABHT28O8/9aBL5mSHOu/dDrn1mHhvr1JwkIrtPodBB9c/P5NkfTeKCA/rxz1nLOe7Gt/l8VVmsyxKRDk6h0IGlJge5dsrePHThvlTVNnDKre/x/CerYl2WiHRgCoU4MGlgHs//+ABG9Mzhx498zF9e/oLGsIbHEJGdp1CIE12zUnn4BxOZOqE3t8xYwrn3fsBazePsAAARpUlEQVTaytpYlyUiHYxCIY6kJAX4w3dG8ofvjOT9r9Zx7PVvM3OJRlsVkdZTKMQZM+OMffvw7CWTyAwl8f27ZvG3VxZS26Czk0RkxxQKcWpYj2ye//EBnLxPATdNX8yx17/N7GXrYl2WiLRzUQ0FMzvGzBaa2WIzu7qF1881sxIzmxt5XBjNehJNRiiJv31vNPedN56a+jDfvW0mv37ucw2RISLbFLVQMLMgcDMwGdgbmGpme7cw62POuTGRx13RqieRHTKkK6/+5CDO3b8v9723jBNueocFq8tjXZaItEPRPFKYACx2zi11ztUBjwInRnF5sh0ZoSR+fcJw7jtvPOuq6jnx5ne5460l1DeGY12aiLQj0QyFXsCKZs+LItO2doqZfWpmT5hZ75Y+yMymmdlsM5tdUlISjVoTxiFDuvLK5Qdy0KB8/vDiFxzzj7eYofGTRCQimqFgLUzb+oqq54G+zrlRwGvA/S19kHPuDudcoXOuMD8/fw+XmXhyM0PcefY47j6nkMaw49x7P+SC+z5kxTrd3U0k0UUzFIqA5nv+BcAWYzA450qdc5uusLoTGBfFeqQZM+PwYd145ScHcc3kocxcWsqRf3+TW2Yspq5BTUoiiSqaofAhMMjM+plZCnA68FzzGcysR7OnJwALoliPtCCUFOSigwfw2k8P5uDB+fzl5YUcd4MuehNJVFELBedcA/Aj4BX8xv5x59znZvZbMzshMtulZva5mX0CXAqcG616ZPt6dkrj9rMKufucQjbWNzL1zllc/ujHrKmoiXVpItKGzLmONXBaYWGhmz17dqzLiGsb6xq5ZcZibn9zKaGkANccO4zTx/cmEGipm0hEOgIz+8g5V7ij+XRFs3xLWkqQnx01hJcvP5DhvbL5+dOfMfXOWXy1tirWpYlIlCkUZJv652fyyA8m8seTRzJ/dTlH/+Mt/vff81lfVRfr0kQkShQKsl1mxtQJfXjtpwdzwuie3PPuVxz0l+nc9MYiqmobYl2eiOxh6lOQnfJlcQV/fWUh/5lfTF5mCpccOpAz9u1DKCkY69JEZDvUpyBRMbhbFneeXciT/7U/g7pm8Zvn53PY397k2bkr6Wg7GCLybQoF2SXj9urMI9Mm8tCF+9I5I5nLHp3L926byWdFZbEuTUR2g0JBdsukgXk8e8kB/PmUkSwrreKEm9/hkofmaBRWkQ4qKdYFSMcXDBinje/D5JE9uG3GEh6YuZwXPlvNkXt344cHD2DcXp1jXaKItJI6mmWP21Bdx73vLuPed7+ivKaBMb07cf4B/Th2RHeSgjo4FYmF1nY0KxQkaqpqG3hyThH3vruMr9ZWMbBrJj8/diiHDumKma6OFmlLCgVpN8Jhx6vzi/nzy1/w1doqJg3M5eJDBjKxfy5BDZ0h0iYUCtLu1DeGeWjWcq5/fRHrq+vpmhXiuFE9OG18b4Z2z451eSJxTaEg7VZNfSOvL1jDc5+sZPoXJdQ1hjlkSD7TDurPfv1z1bQkEgUKBekQNlTX8dD7X3Pvu1+xtrKOYT2yOa2wgJPG9qJTekqsyxOJGwoF6VBq6ht5as5KHv5gOfNWlpOSFODo4d05rbA3+w/I1bDdIrtJoSAd1uerynj8wxU8M3cVZRvrKeicxin7FHDimJ70z8+MdXkiHZJCQTq8mvpGXp1fzOMfruDdJWtxDkYV5HDimF6cMLon+VmhWJco0mEoFCSufFNWw78/XcUzc1cyb2U5wYBxyOB8vrNPLw4d0pWMkC7OF9kehYLErUXFFTw5ZyVPf1xEcXktoaQABw3OZ/KI7hw2tKs6qEVaoFCQuNcYdny4bB0vz/uGl+d9wzflNQQDRuFenTly724cOCifwd0ydYqrCAoFSTDhsOOzlWX8Z34x/5lfzMLiCgDys0LsPyCXAwflc9CgPLpmp8a4UpHYUChIQitaX817i0t5d8la3l28lrWV/r7Sw3pkc9jQfA4b2o0xvTtpmA1JGAoFkYhw2DF/dTlvLSrhzYUlzF6+nsawo0tGCmN7d2JErxxG9sphfN8u5KQnx7pckahQKIhsQ9nGet76soQZC0v4tGgDS0oqCTsIGIzu3YkDB+UzoW8XRvbKUUhI3FAoiLRSdV0DnxWV8e6SUt760gdFOPJnsVduOiN75TC6oBOjCnIY3iuHTJ3+Kh2QQkFkF5VV1/PZyjI+XbmBT1eU8dnKMlZu2AiAGfTNzWDvntmM6pVDYd/OjOiVQygpGOOqRbavtaGgXR6RreSkJ3PAoDwOGJTXNG1tZS2fFm1g3spyPl9VxicrNvDCp6sBSAkGGNYzm8FdMxncLYvB3bMY0i2LbtkhnQ4rHY6OFER2UUlFLXO+Xs9Hy9fz+aoyviyupKSitun1nLRkBnfLpH9eJv3zM+ifn0m/vHR6d0nXkYW0OR0piERZflaIo4d35+jh3Zumra+qY2FxBQu/qWBhcQWLiit4bUExpbPrmuYxg545afTLy6BvXjp9czMY1C2LQV0z6ZGTqqMLiSmFgsge1DkjhYn9c5nYP3eL6WXV9SxdW8my0iq+WlvNsrVVLC+t4rm5qyivaWiaLyMlSPecVLplp9I1K0S3nFR6ZKfSPSeN/vkZ9M3NICUp0NarJQlEoSDSBnLSkxnbpzNj+3TeYrpzjnVVdSxaU8miNZUsWVNJcXkNaypqmb18PWvKa6lrDDfNnxQw+uVl0D0nlS4ZKXROTyEvM4X8rBD5WSFyM0J0yUghNzOF9BT9ecvO0/8akRgyM3IzQ+Rmhr51dAH+wrt11XWs3lDD4pIKviyuZFFxJSWVtSwvrWZdVR2VtQ0tfDJkhpLonpNKj5xUHxqZkeDITKFLRogu6SnkpCWTFDSSgwEyQkEFiSgURNqzQMDIywyRlxliZEFOi/PU1DeytrKWkopa1lXVUVpZR2lVHWsqavimrIZVZTUsWVPJ2sq6LY46WpKbkUJBl3S6ZYVw+FAyg/wsHy7dskNkpyaTEUoiMzWJ1KQgqckB0lKCdE5PITVZHegdnUJBpINLTQ5S0Dmdgs7p253POUd5TQNrK2vZUO3Do6KmgfrGMPVhR/nGeorWV7Ni3UaWl1YTCBjBADSGYe6KDU3jR21PekqQLhkphJICBANGMBAgIyVIdloy2alJpCYHSQoaSYEAoeQAWaEkMjY9UpJIDwVJTw6SlhIkNTlIcjBAY9jhnCMpGKBLegrZaUnqjI8ihYJIgjAzctKSyUnbtaE7ahsaKamopaKmgaraBipqG6ipa6SmoZGNdWHWV9exrso/6hrCNIYdDWFHdV0DaypqWLSmntp6P72+MUxNfXiHRy4tSQpYU7NX0IxgJGSSAkZSMEAoyT9SkgIEIuFhBhkpSWSlJpEZSiIpGCAYgKAZZoYZBMwIJQVITwmSlpJEKGnzZyYFDCLzWOTzDCM5aKRHwiyUFPCfhZ/Ph5/5cDXz7zVIDgba9UCMCgURaZVQUnCHRyM7q7ahkaraRqpqG6iua6SqroGNdY3U1Deysb6RhkbffBUMGPWNYUorfeiUbaxvCp1N/zY0hqlvdNQ1hqmtb6SipoFNV2GFw44VddVU1jZQWdNAfdgRDjsanSMWl2qZQXIgAD5rfIgEtgy4gBE5WrNIeMHUCX248MD+Ua1NoSAiMRNKChJK8k1OseIiwRB2jtqGMNV1jVTXNVDXEI6EjQ+PcGQ+5xwOcA7qGzfPX1sfxrHps6AxvPn9DheZ5p83hH2AORxElr0p4OobHY3hMGFHU3CFI/O0xX3JFQoiktCamo/wTUX+ft/R3/i2V7oKRkREmkQ1FMzsGDNbaGaLzezqFl4PmdljkdffN7O+0axHRES2L2qhYGZB4GZgMrA3MNXM9t5qtguA9c65gcDfgT9Hqx4REdmxaB4pTAAWO+eWOufqgEeBE7ea50Tg/sjPTwCHm05AFhGJmWiGQi9gRbPnRZFpLc7jnGsAyoBvXetvZtPMbLaZzS4pKYlSuSIiEs1QaGmPf+szglszD865O5xzhc65wvz8/D1SnIiIfFs0Q6EI6N3seQGwalvzmFkSkAOsi2JNIiKyHdEMhQ+BQWbWz8xSgNOB57aa5zngnMjP3wXecB3tVnAiInEkqrfjNLNjgX8AQeAe59zvzey3wGzn3HNmlgr8ExiLP0I43Tm3dAefWQIs38WS8oC1u/jejiwR1zsR1xkSc70TcZ1h59d7L+fcDtvfO9w9mneHmc1uzT1K400irncirjMk5non4jpD9NZbVzSLiEgThYKIiDRJtFC4I9YFxEgirncirjMk5non4jpDlNY7ofoURERk+xLtSEFERLZDoSAiIk0SJhR2NIx3PDCz3mY23cwWmNnnZnZZZHoXM/uPmS2K/Ns51rVGg5kFzexjM/t35Hm/yJDsiyJDtMfu9l5RYGadzOwJM/si8p3vlwjftZn9JPL/e56ZPWJmqfH4XZvZPWa2xszmNZvW4vdr3g2R7dunZrbPri43IUKhlcN4x4MG4GfOuWHAROCSyHpeDbzunBsEvB55Ho8uAxY0e/5n4O+R9V6PH6o9nlwPvOycGwqMxq97XH/XZtYLuBQodM6NwF8Yezrx+V3fBxyz1bRtfb+TgUGRxzTg1l1daEKEAq0bxrvDc86tds7Nifxcgd9I9GLLIcrvB06KTYXRY2YFwHHAXZHnBhyGH5Id4my9zSwbOAi4G8A5V+ec20ACfNf42winRcZLSwdWE4fftXPuLb49Fty2vt8TgQecNwvoZGY9dmW5iRIKrRnGO65E7mI3Fngf6OacWw0+OICusassav4B/DcQjjzPBTZEhmSH+PvO+wMlwL2RJrO7zCyDOP+unXMrgb8BX+PDoAz4iPj+rpvb1ve7x7ZxiRIKrRqiO16YWSbwJHC5c6481vVEm5lNAdY45z5qPrmFWePpO08C9gFudc6NBaqIs6ailkTa0E8E+gE9gQx808nW4um7bo099v89UUKhNcN4xwUzS8YHwkPOuacik4s3HUpG/l0Tq/qiZBJwgpktwzcNHoY/cugUaWKA+PvOi4Ai59z7kedP4EMi3r/rI4CvnHMlzrl64Clgf+L7u25uW9/vHtvGJUootGYY7w4v0o5+N7DAOXdds5eaD1F+DvBsW9cWTc65a5xzBc65vvjv9g3n3PeB6fgh2SHO1ts59w2wwsyGRCYdDswnzr9rfLPRRDNLj/x/37Tecftdb2Vb3+9zwNmRs5AmAmWbmpl2VsJc0dzSMN4xLmmPM7MDgLeBz9jctv5zfL/C40Af/B/V95xzcXkzIzM7BLjCOTfFzPrjjxy6AB8DZzrnamNZ355kZmPwHespwFLgPPyOXlx/12b2G+A0/Nl2HwMX4tvP4+q7NrNHgEPwQ2QXA78CnqGF7zcSkDfhz1aqBs5zzs3epeUmSiiIiMiOJUrzkYiItIJCQUREmigURESkiUJBRESaKBRERKSJQkGkDZnZIZtGcRVpjxQKIiLSRKEg0gIzO9PMPjCzuWZ2e+ReDZVm9n9mNsfMXjez/Mi8Y8xsVmQc+6ebjXE/0MxeM7NPIu8ZEPn4zGb3QXgocuGRSLugUBDZipkNw18xO8k5NwZoBL6PH3xtjnNuH+BN/BWmAA8AVznnRuGvJt80/SHgZufcaPz4PJuGHRgLXI6/t0d//NhNIu1C0o5nEUk4hwPjgA8jO/Fp+IHHwsBjkXkeBJ4ysxygk3Puzcj0+4F/mVkW0Ms59zSAc64GIPJ5HzjniiLP5wJ9gXeiv1oiO6ZQEPk2A+53zl2zxUSza7eab3tjxGyvSaj5mDyN6O9Q2hE1H4l82+vAd82sKzTdF3cv/N/LppE4zwDecc6VAevN7MDI9LOANyP3sSgys5MinxEys/Q2XQuRXaA9FJGtOOfmm9kvgFfNLADUA5fgb2Qz3Mw+wt/x67TIW84Bbots9DeNVgo+IG43s99GPuN7bbgaIrtEo6SKtJKZVTrnMmNdh0g0qflIRESa6EhBRESa6EhBRESaKBRERKSJQkFERJooFEREpIlCQUREmvw/UziuC0jmVwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajdeep\\AppData\\Local\\conda\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\engine\\topology.py:2379: UserWarning: Layer lstm_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_2/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('s2s2000SamplesWordLevel-Update30-4-18-11-14am.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Model (Sampling sequences)\n",
    "# For sampling the sequences here is the strategy to be followed\n",
    "\n",
    "# 1. Encode the input and retrieve the initial encoder state\n",
    "# 2. Run one step of the decoder with its initial encoder state and a \"start of sequence\" token as target\n",
    "# 3. Output will be the next target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original keras example, they are using the training examples themselves to predict the french statements\n",
    "# However we would like to use predict new statements\n",
    "# For this we would have to change a few things in order to achieve what we need to achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i now:0\n",
      "i now:1\n"
     ]
    }
   ],
   "source": [
    "# preparing the test data\n",
    "test_data_path = os.path.join(os.path.dirname(os.getcwd()), \"datasets\", \"fra-eng\", \"fra-test.txt\") # path to the test \n",
    "# corpus file\n",
    "test_input_texts = []\n",
    "with open(test_data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split(\"\\n\") # spliting training examples\n",
    "\n",
    "# remember we are trying to get only `sample` number of lines and not any more for training \n",
    "for line in lines:\n",
    "    input_text = line\n",
    "    \n",
    "#     target_text = '\\t' + target_text + \"\\n\"\n",
    "    \n",
    "    test_input_texts.append(input_text)\n",
    "#     target_texts.append(target_text)\n",
    "    \n",
    "encoder_test_input_data = np.zeros((len(test_input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (test_input_text) in enumerate(test_input_texts):\n",
    "    print(\"i now:\" + str(i))\n",
    "    test_input_text = test_input_text.split(\" \")\n",
    "    for t, word in enumerate(test_input_text):\n",
    "        # i is the first index as it is the ith training example \n",
    "        # t is the second index as the t-th character in ith training example\n",
    "#         print(\"t, char now: \" + str(t) + \", \" + str(char))\n",
    "    \n",
    "        if \".\" in word: # patchy method of considering punctuations '.' and ',' as separate words\n",
    "            period_split_words = word.split(\".\")\n",
    "            encoder_test_input_data[i, t, input_token_index[\".\"]] = 1\n",
    "            encoder_test_input_data[i, t, input_token_index[period_split_words[1]]] = 1\n",
    "        else:\n",
    "            encoder_test_input_data[i, t, input_token_index[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_input_char_index = dict(\n",
    "#     (i, char) for char, i in input_token_index.items())\n",
    "# reverse_target_char_index = dict(\n",
    "#     (i, char) for char, i in target_token_index.items())\n",
    "reverse_input_word_index = dict(\n",
    "    (i, word) for word, i in input_token_index.items())\n",
    "reverse_target_word_index = dict(\n",
    "    (i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \"\"\"\n",
    "    This function is for decoding a sequence of english letters\n",
    "    \"\"\"\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq) # this is actually encoder_input data\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    \n",
    "    # target_sequence is simply a one hot vector of size vocab size\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        # predicting one character at a time\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_target_word_index[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence:  No Cheers!\n",
      "Decoded sentence:   n'en !\n",
      "\n",
      "-\n",
      "Input sentence:  Jump. on.\n",
      "Decoded sentence:    rouler\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(2):\n",
    "    # this trick below is just for converting input_seq to a list\n",
    "    input_seq = encoder_test_input_data[seq_index: seq_index + 1] # we will need to form a new encoder_input_data\n",
    "    decoded_sentence = decode_sequence(input_seq=input_seq)\n",
    "    print('-')\n",
    "    print(\"Input sentence: \", test_input_texts[seq_index])\n",
    "    print(\"Decoded sentence: \", decoded_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
